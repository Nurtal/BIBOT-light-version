Recognizing the samples belonging to one class in a heterogeneous data set is a very interesting but tough machine learning task. Some samples of the data set can be actual outliers or members of other classes for which training examples are lacking. In contrast to other kernel approaches present in the literature, in this work, the problem is faced defining a one-class kernel machine that delivers the probability for a sample to belong to the support of the distribution and that can be efficiently trained by a hybrid sequential minimal optimization-expectation maximization algorithm. Due to the analogy to the import vector machine and to the one-class approach, we named the method import vector domain description (IVDD). IVDD was tested on a toy 2-D data set in order to characterize its behavior on a set of widely used benchmarking UCI data sets and, lastly, challenged against a real world outlier detection data set. All the results were compared against state-of-the-art closely related methods such as one-class-SVM and Support Vector Domain Description, proving that the algorithm is equally accurate with the additional advantage of delivering the probability estimate for each sample. Finally, a few variants aimed at providing memory savings and/or computational speed-up in the light of big data analysis are briefly sketched.